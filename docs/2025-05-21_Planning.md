# Catalyzer Development Planning Document
**Date: May 21, 2025**

## Current System Status

Catalyzer is a catalog system for data lakes that currently provides:

- Backend service (`Catalyzer::Cabinet`) for managing catalog entries
- CRUD operations for catalog markdown files
- Search functionality with tag-based and full-text search
- DuckDB-based storage
- Support for markdown files with YAML frontmatter

## Development Goals for May 21, 2025

Building upon the existing foundation, the following goals are set for this development phase:

1. Implement robust data file detection and crawling capabilities
2. Enhance catalog generation automation
3. Improve search and discovery features
4. Begin development of the Web UI
5. Implement metadata extension framework

## Technical Tasks and Subtasks

### 1. Data File Detection and Crawling

**Purpose**: Detect new/updated data in the Datalake and identify targets for catalog generation.

#### Subtasks:
- [ ] Design crawler architecture to scan configurable datalake paths
- [ ] Implement file change detection (new/modified files)
- [ ] Create metadata extraction system for various file formats (CSV, JSON, Parquet, etc.)
- [ ] Develop scheduling system for regular crawling
- [ ] Build notification system for newly discovered data
- [ ] Implement crawler configuration interface

### 2. Catalog Generation Automation

**Purpose**: Automate the creation of markdown catalog files based on discovered data.

#### Subtasks:
- [ ] Extend the catalog creation service to handle batch operations
- [ ] Create template system for different data types
- [ ] Implement automatic metadata extraction for YAML frontmatter
  - File name, size, and update timestamps
  - Content-based metadata (schema inference)
  - Ownership and access information
- [ ] Build validation system for generated catalogs
- [ ] Develop hook system for custom metadata additions

### 3. Search and Discovery Enhancement

**Purpose**: Improve the ability to find and discover data assets.

#### Subtasks:
- [ ] Implement faceted search capabilities
- [ ] Add support for hierarchical tags
- [ ] Create category-based browsing interface
- [ ] Enhance full-text search with ranking and relevance scoring
- [ ] Add support for saved searches and alerts

### 4. Web UI Development

**Purpose**: Create an intuitive interface for catalog browsing and management.

#### Subtasks:
- [ ] Design UI wireframes and user flow
- [ ] Implement catalog browsing interface
- [ ] Build catalog detail view with metadata display
- [ ] Create search interface with filters
- [ ] Develop user authentication and authorization system
- [ ] Implement catalog editing capabilities
- [ ] Build dashboard for system statistics and metrics

### 5. Metadata Extension Framework

**Purpose**: Allow flexible addition of metadata fields as requirements evolve.

#### Subtasks:
- [ ] Design schema for extensible metadata fields
- [ ] Implement validation system for custom metadata
- [ ] Create API endpoints for metadata schema management
- [ ] Build UI components for custom metadata configuration
- [ ] Develop documentation system for metadata fields

## Implementation Priorities

1. **High Priority**:
   - Data file detection and crawling core functionality
   - Basic Web UI for browsing catalogs
   - Search enhancement

2. **Medium Priority**:
   - Metadata extension framework
   - Advanced catalog generation features
   - Notification system

3. **Low Priority**:
   - UI customization options
   - Advanced statistics and analytics
   - Integration with external systems

## Resource Requirements

- **Development Team**:
  - 2 Backend Developers
  - 1 Frontend Developer
  - 1 Data Engineer

- **Infrastructure**:
  - Expanded storage capacity for catalog entries
  - Compute resources for crawling operations
  - CI/CD pipeline enhancements

## Timeline

| Week | Focus Area | Deliverables |
|------|------------|--------------|
| 1-2 | Data Crawling | Basic crawler functionality |
| 3-4 | Catalog Generation | Automated catalog creation from detected files |
| 5-6 | Web UI | Basic browsing interface |
| 7-8 | Search Enhancement | Improved search capabilities |
| 9-10 | Metadata Extension | Framework for custom metadata |

## Next Steps

1. Finalize technical specifications for data crawler
2. Create detailed mockups for Web UI
3. Set up development environments
4. Establish sprint planning and task allocation

## Conclusion

This plan outlines the key development activities for Catalyzer scheduled for May 21, 2025. The focus is on expanding the system's capabilities while maintaining its core principles of efficient data asset organization and discovery.